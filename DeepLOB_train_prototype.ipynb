{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.utils import class_weight\n",
    "import os\n",
    "import itertools\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = './datasets/train/'\n",
    "validate_dir = './datasets/validate/'\n",
    "datasample_period = 60\n",
    "prediction_period = 10\n",
    "feature_columns = 40\n",
    "band_size = 0.001\n",
    "temp = 200\n",
    "n_train_files = len(os.listdir(train_dir))\n",
    "n_validate_files = len(os.listdir(validate_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a directory to store all the checkpoints.\n",
    "checkpoint_dir = './models/checkpoint'\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(directory, sample_size, prediction_period, feature_num, band_size):\n",
    "    for subdir, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith((\".npy\")):\n",
    "                data = np.load(os.path.join(subdir, file))[:temp]\n",
    "                # generate X, Y\n",
    "                shape = data.shape\n",
    "                X = np.zeros((shape[0]-sample_size, sample_size, feature_num), dtype=np.float16)\n",
    "                Y = np.zeros(shape=(shape[0]-sample_size, 1), dtype=np.int)\n",
    "                for i in range(shape[0]-sample_size):\n",
    "                    # take the first feature_num columns as features\n",
    "                    X[i] = data[i:i+sample_size, 1:feature_num+1]\n",
    "                    delta_last = (data[i+sample_size-1, 0] - data[i, 0]) / data[i+sample_size-1, 0]\n",
    "                    if delta_last < -band_size:\n",
    "                        Y[i] = 0\n",
    "                    elif delta_last > band_size:\n",
    "                        Y[i] = 2\n",
    "                    else:\n",
    "                        Y[i] = 1\n",
    "                # add the 4th dimension: 1 channel\n",
    "                X = X.reshape(X.shape[0], sample_size, feature_num, 1)\n",
    "                \n",
    "                # calculate sample_weights for Y\n",
    "                sample_weights_y = np.append(Y.flatten(), [0,1,2]) # to ensure exhaustive coverage\n",
    "                sample_weights_categories = class_weight.compute_class_weight('balanced', classes = np.unique(sample_weights_y), y=sample_weights_y)\n",
    "                idx = 0\n",
    "                sample_weights = np.zeros(shape[0]-sample_size)\n",
    "                for y in Y.flatten(): \n",
    "                    sample_weights[idx] = sample_weights_categories[y]\n",
    "                    idx += 1\n",
    "\n",
    "                # transform y to categorical arrays\n",
    "                y_labels = to_categorical(sample_weights_y)[:-3]\n",
    "\n",
    "                yield X, y_labels, sample_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = generate_data(train_dir, datasample_period, prediction_period, feature_columns, band_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[[3.7201e-02],\n",
       "          [4.0750e+01],\n",
       "          [3.7262e-02],\n",
       "          ...,\n",
       "          [3.2031e+01],\n",
       "          [3.7598e-02],\n",
       "          [1.4602e+01]],\n",
       " \n",
       "         [[3.7201e-02],\n",
       "          [4.0812e+01],\n",
       "          [3.7262e-02],\n",
       "          ...,\n",
       "          [3.2031e+01],\n",
       "          [3.7598e-02],\n",
       "          [1.4602e+01]],\n",
       " \n",
       "         [[3.7201e-02],\n",
       "          [3.6344e+01],\n",
       "          [3.7262e-02],\n",
       "          ...,\n",
       "          [3.0578e+01],\n",
       "          [3.7598e-02],\n",
       "          [1.4391e+01]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[3.7201e-02],\n",
       "          [4.8344e+01],\n",
       "          [3.7262e-02],\n",
       "          ...,\n",
       "          [3.0594e+01],\n",
       "          [3.7598e-02],\n",
       "          [1.4555e+01]],\n",
       " \n",
       "         [[3.7170e-02],\n",
       "          [8.0875e+01],\n",
       "          [3.7262e-02],\n",
       "          ...,\n",
       "          [3.8656e+01],\n",
       "          [3.7598e-02],\n",
       "          [2.9266e+01]],\n",
       " \n",
       "         [[3.7170e-02],\n",
       "          [8.7875e+01],\n",
       "          [3.7262e-02],\n",
       "          ...,\n",
       "          [3.8625e+01],\n",
       "          [3.7598e-02],\n",
       "          [2.9922e+01]]],\n",
       " \n",
       " \n",
       "        [[[3.7201e-02],\n",
       "          [4.0812e+01],\n",
       "          [3.7262e-02],\n",
       "          ...,\n",
       "          [3.2031e+01],\n",
       "          [3.7598e-02],\n",
       "          [1.4602e+01]],\n",
       " \n",
       "         [[3.7201e-02],\n",
       "          [3.6344e+01],\n",
       "          [3.7262e-02],\n",
       "          ...,\n",
       "          [3.0578e+01],\n",
       "          [3.7598e-02],\n",
       "          [1.4391e+01]],\n",
       " \n",
       "         [[3.7170e-02],\n",
       "          [6.2750e+01],\n",
       "          [3.7262e-02],\n",
       "          ...,\n",
       "          [4.0469e+01],\n",
       "          [3.7598e-02],\n",
       "          [2.8297e+01]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[3.7170e-02],\n",
       "          [8.0875e+01],\n",
       "          [3.7262e-02],\n",
       "          ...,\n",
       "          [3.8656e+01],\n",
       "          [3.7598e-02],\n",
       "          [2.9266e+01]],\n",
       " \n",
       "         [[3.7170e-02],\n",
       "          [8.7875e+01],\n",
       "          [3.7262e-02],\n",
       "          ...,\n",
       "          [3.8625e+01],\n",
       "          [3.7598e-02],\n",
       "          [2.9922e+01]],\n",
       " \n",
       "         [[3.7170e-02],\n",
       "          [8.5812e+01],\n",
       "          [3.7262e-02],\n",
       "          ...,\n",
       "          [3.8688e+01],\n",
       "          [3.7598e-02],\n",
       "          [2.9922e+01]]],\n",
       " \n",
       " \n",
       "        [[[3.7201e-02],\n",
       "          [3.6344e+01],\n",
       "          [3.7262e-02],\n",
       "          ...,\n",
       "          [3.0578e+01],\n",
       "          [3.7598e-02],\n",
       "          [1.4391e+01]],\n",
       " \n",
       "         [[3.7170e-02],\n",
       "          [6.2750e+01],\n",
       "          [3.7262e-02],\n",
       "          ...,\n",
       "          [4.0469e+01],\n",
       "          [3.7598e-02],\n",
       "          [2.8297e+01]],\n",
       " \n",
       "         [[3.7170e-02],\n",
       "          [5.6125e+01],\n",
       "          [3.7231e-02],\n",
       "          ...,\n",
       "          [3.9500e+01],\n",
       "          [3.7567e-02],\n",
       "          [3.0859e+01]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[3.7170e-02],\n",
       "          [8.7875e+01],\n",
       "          [3.7262e-02],\n",
       "          ...,\n",
       "          [3.8625e+01],\n",
       "          [3.7598e-02],\n",
       "          [2.9922e+01]],\n",
       " \n",
       "         [[3.7170e-02],\n",
       "          [8.5812e+01],\n",
       "          [3.7262e-02],\n",
       "          ...,\n",
       "          [3.8688e+01],\n",
       "          [3.7598e-02],\n",
       "          [2.9922e+01]],\n",
       " \n",
       "         [[3.7170e-02],\n",
       "          [1.1819e+02],\n",
       "          [3.7262e-02],\n",
       "          ...,\n",
       "          [3.9562e+01],\n",
       "          [3.7598e-02],\n",
       "          [2.9344e+01]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[3.7201e-02],\n",
       "          [8.5125e+01],\n",
       "          [3.7292e-02],\n",
       "          ...,\n",
       "          [1.6925e+02],\n",
       "          [3.7628e-02],\n",
       "          [1.1156e+01]],\n",
       " \n",
       "         [[3.7201e-02],\n",
       "          [1.0506e+02],\n",
       "          [3.7262e-02],\n",
       "          ...,\n",
       "          [8.6625e+01],\n",
       "          [3.7598e-02],\n",
       "          [1.4656e+01]],\n",
       " \n",
       "         [[3.7201e-02],\n",
       "          [1.5125e+02],\n",
       "          [3.7262e-02],\n",
       "          ...,\n",
       "          [1.5025e+02],\n",
       "          [3.7598e-02],\n",
       "          [1.5523e+01]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[3.7079e-02],\n",
       "          [1.2075e+02],\n",
       "          [3.7170e-02],\n",
       "          ...,\n",
       "          [4.3219e+01],\n",
       "          [3.7506e-02],\n",
       "          [4.3325e+02]],\n",
       " \n",
       "         [[3.7109e-02],\n",
       "          [1.3625e+02],\n",
       "          [3.7170e-02],\n",
       "          ...,\n",
       "          [3.8000e+01],\n",
       "          [3.7506e-02],\n",
       "          [2.7031e+01]],\n",
       " \n",
       "         [[3.7109e-02],\n",
       "          [1.1325e+02],\n",
       "          [3.7170e-02],\n",
       "          ...,\n",
       "          [7.0812e+01],\n",
       "          [3.7506e-02],\n",
       "          [2.5172e+01]]],\n",
       " \n",
       " \n",
       "        [[[3.7201e-02],\n",
       "          [1.0506e+02],\n",
       "          [3.7262e-02],\n",
       "          ...,\n",
       "          [8.6625e+01],\n",
       "          [3.7598e-02],\n",
       "          [1.4656e+01]],\n",
       " \n",
       "         [[3.7201e-02],\n",
       "          [1.5125e+02],\n",
       "          [3.7262e-02],\n",
       "          ...,\n",
       "          [1.5025e+02],\n",
       "          [3.7598e-02],\n",
       "          [1.5523e+01]],\n",
       " \n",
       "         [[3.7201e-02],\n",
       "          [7.2125e+01],\n",
       "          [3.7262e-02],\n",
       "          ...,\n",
       "          [9.7062e+01],\n",
       "          [3.7598e-02],\n",
       "          [3.0797e+01]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[3.7109e-02],\n",
       "          [1.3625e+02],\n",
       "          [3.7170e-02],\n",
       "          ...,\n",
       "          [3.8000e+01],\n",
       "          [3.7506e-02],\n",
       "          [2.7031e+01]],\n",
       " \n",
       "         [[3.7109e-02],\n",
       "          [1.1325e+02],\n",
       "          [3.7170e-02],\n",
       "          ...,\n",
       "          [7.0812e+01],\n",
       "          [3.7506e-02],\n",
       "          [2.5172e+01]],\n",
       " \n",
       "         [[3.7079e-02],\n",
       "          [1.2538e+02],\n",
       "          [3.7170e-02],\n",
       "          ...,\n",
       "          [4.2656e+01],\n",
       "          [3.7506e-02],\n",
       "          [4.3325e+02]]],\n",
       " \n",
       " \n",
       "        [[[3.7201e-02],\n",
       "          [1.5125e+02],\n",
       "          [3.7262e-02],\n",
       "          ...,\n",
       "          [1.5025e+02],\n",
       "          [3.7598e-02],\n",
       "          [1.5523e+01]],\n",
       " \n",
       "         [[3.7201e-02],\n",
       "          [7.2125e+01],\n",
       "          [3.7262e-02],\n",
       "          ...,\n",
       "          [9.7062e+01],\n",
       "          [3.7598e-02],\n",
       "          [3.0797e+01]],\n",
       " \n",
       "         [[3.7201e-02],\n",
       "          [1.2975e+02],\n",
       "          [3.7262e-02],\n",
       "          ...,\n",
       "          [9.0750e+01],\n",
       "          [3.7598e-02],\n",
       "          [1.4555e+01]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[3.7109e-02],\n",
       "          [1.1325e+02],\n",
       "          [3.7170e-02],\n",
       "          ...,\n",
       "          [7.0812e+01],\n",
       "          [3.7506e-02],\n",
       "          [2.5172e+01]],\n",
       " \n",
       "         [[3.7079e-02],\n",
       "          [1.2538e+02],\n",
       "          [3.7170e-02],\n",
       "          ...,\n",
       "          [4.2656e+01],\n",
       "          [3.7506e-02],\n",
       "          [4.3325e+02]],\n",
       " \n",
       "         [[3.7079e-02],\n",
       "          [1.3988e+02],\n",
       "          [3.7170e-02],\n",
       "          ...,\n",
       "          [4.2656e+01],\n",
       "          [3.7506e-02],\n",
       "          [4.3325e+02]]]], dtype=float16),\n",
       " array([[0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.]], dtype=float32),\n",
       " array([0.54166667, 0.54166667, 0.54166667, 0.54166667, 0.54166667,\n",
       "        0.54166667, 0.54166667, 0.54166667, 0.54166667, 0.54166667,\n",
       "        0.54166667, 0.54166667, 1.58888889, 1.58888889, 1.58888889,\n",
       "        0.54166667, 0.54166667, 0.54166667, 0.54166667, 0.54166667,\n",
       "        0.54166667, 0.54166667, 1.58888889, 1.58888889, 1.58888889,\n",
       "        0.54166667, 0.54166667, 0.54166667, 0.54166667, 0.54166667,\n",
       "        0.54166667, 0.54166667, 0.54166667, 0.54166667, 0.54166667,\n",
       "        1.58888889, 1.58888889, 1.58888889, 1.58888889, 1.58888889,\n",
       "        1.58888889, 1.58888889, 0.54166667, 0.54166667, 0.54166667,\n",
       "        0.54166667, 0.54166667, 0.54166667, 0.54166667, 0.54166667,\n",
       "        0.54166667, 0.54166667, 0.54166667, 0.54166667, 0.54166667,\n",
       "        0.54166667, 0.54166667, 0.54166667, 0.54166667, 0.54166667,\n",
       "        0.54166667, 0.54166667, 0.54166667, 0.54166667, 0.54166667,\n",
       "        0.54166667, 0.54166667, 0.54166667, 0.54166667, 1.90666667,\n",
       "        1.90666667, 1.90666667, 1.90666667, 1.90666667, 1.90666667,\n",
       "        1.90666667, 1.90666667, 0.54166667, 1.90666667, 1.90666667,\n",
       "        1.90666667, 1.90666667, 1.90666667, 1.90666667, 0.54166667,\n",
       "        1.90666667, 1.90666667, 0.54166667, 0.54166667, 0.54166667,\n",
       "        0.54166667, 1.90666667, 0.54166667, 0.54166667, 1.90666667,\n",
       "        1.90666667, 1.90666667, 1.90666667, 1.90666667, 1.90666667,\n",
       "        1.90666667, 0.54166667, 0.54166667, 0.54166667, 0.54166667,\n",
       "        0.54166667, 0.54166667, 0.54166667, 0.54166667, 0.54166667,\n",
       "        0.54166667, 0.54166667, 0.54166667, 0.54166667, 0.54166667,\n",
       "        0.54166667, 0.54166667, 0.54166667, 0.54166667, 0.54166667,\n",
       "        0.54166667, 0.54166667, 0.54166667, 0.54166667, 1.58888889,\n",
       "        1.58888889, 1.58888889, 1.58888889, 1.58888889, 1.58888889,\n",
       "        1.58888889, 1.58888889, 1.58888889, 1.58888889, 1.58888889,\n",
       "        1.58888889, 1.58888889, 1.58888889, 1.58888889, 1.58888889]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = next(batch)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140, 60, 40, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(datasample_period, feature_columns):\n",
    "    input_tensor = Input(shape=(datasample_period,feature_columns,1))\n",
    "\n",
    "    # convolutional filter is (1,2) with stride of (1,2)\n",
    "    layer_x = layers.Conv2D(16, (1,2), strides=(1,2))(input_tensor)\n",
    "    layer_x = layers.LeakyReLU(alpha=0.01)(layer_x)\n",
    "    layer_x = layers.Conv2D(16, (4,1), padding='same')(layer_x)\n",
    "    layer_x = layers.LeakyReLU(alpha=0.01)(layer_x)\n",
    "    layer_x = layers.Conv2D(16, (4,1), padding='same')(layer_x)\n",
    "    layer_x = layers.LeakyReLU(alpha=0.01)(layer_x)\n",
    "\n",
    "    layer_x = layers.Conv2D(16, (1,2), strides=(1,2))(layer_x)\n",
    "    layer_x = layers.LeakyReLU(alpha=0.01)(layer_x)\n",
    "    layer_x = layers.Conv2D(16, (4,1), padding='same')(layer_x)\n",
    "    layer_x = layers.LeakyReLU(alpha=0.01)(layer_x)\n",
    "    layer_x = layers.Conv2D(16, (4,1), padding='same')(layer_x)\n",
    "    layer_x = layers.LeakyReLU(alpha=0.01)(layer_x)\n",
    "\n",
    "    layer_x = layers.Conv2D(16, (1,10))(layer_x)\n",
    "    layer_x = layers.LeakyReLU(alpha=0.01)(layer_x)\n",
    "    layer_x = layers.Conv2D(16, (4,1), padding='same')(layer_x)\n",
    "    layer_x = layers.LeakyReLU(alpha=0.01)(layer_x)\n",
    "    layer_x = layers.Conv2D(16, (4,1), padding='same')(layer_x)\n",
    "    layer_x = layers.LeakyReLU(alpha=0.01)(layer_x)\n",
    "\n",
    "    # Inception Module\n",
    "    tower_1 = layers.Conv2D(32, (1,1), padding='same')(layer_x)\n",
    "    tower_1 = layers.LeakyReLU(alpha=0.01)(tower_1)\n",
    "    tower_1 = layers.Conv2D(32, (3,1), padding='same')(tower_1)\n",
    "    tower_1 = layers.LeakyReLU(alpha=0.01)(tower_1)\n",
    "\n",
    "    tower_2 = layers.Conv2D(32, (1,1), padding='same')(layer_x)\n",
    "    tower_2 = layers.LeakyReLU(alpha=0.01)(tower_2)\n",
    "    tower_2 = layers.Conv2D(32, (5,1), padding='same')(tower_2)\n",
    "    tower_2 = layers.LeakyReLU(alpha=0.01)(tower_2)  \n",
    "\n",
    "    tower_3 = layers.MaxPooling2D((3,1), padding='same', strides=(1,1))(layer_x)\n",
    "    tower_3 = layers.Conv2D(32, (1,1), padding='same')(tower_3)\n",
    "    tower_3 = layers.LeakyReLU(alpha=0.01)(tower_3)\n",
    "\n",
    "    layer_x = layers.concatenate([tower_1, tower_2, tower_3], axis=-1)\n",
    "\n",
    "    # concatenate features of tower_1, tower_2, tower_3\n",
    "    layer_x = layers.Reshape((datasample_period,96))(layer_x)\n",
    "\n",
    "    # 64 LSTM units\n",
    "    layer_x = LSTM(64)(layer_x)\n",
    "    # The last output layer uses a softmax activation function\n",
    "    output = layers.Dense(3, activation='softmax')(layer_x)\n",
    "    model = Model(input_tensor, output)\n",
    "\n",
    "    model.summary()\n",
    "    model.initial_epoch = 0\n",
    "    opt = tf.keras.optimizers.Adam(lr=0.01, epsilon=1) # learning rate and epsilon are the same as paper DeepLOB\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_or_restore_model(datasample_period,feature_columns):\n",
    "    # Either restore the latest model, or create a fresh one\n",
    "    # if there is no checkpoint available.\n",
    "    checkpoints = [checkpoint_dir + '/' + name\n",
    "                   for name in os.listdir(checkpoint_dir)]\n",
    "    if checkpoints:\n",
    "        latest_checkpoint = max(checkpoints, key=os.path.getctime)\n",
    "        print('Restoring from', latest_checkpoint)\n",
    "        model = load_model(latest_checkpoint)\n",
    "        print(latest_checkpoint)\n",
    "        model.initial_epoch = int(latest_checkpoint[latest_checkpoint.index(\"epoch=\")+6:])\n",
    "        return model\n",
    "    print('Creating a new model')\n",
    "    return make_model(datasample_period,feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring from ./models/checkpoint/ckpt-loss=0.91-epoch=0004\n",
      "./models/checkpoint/ckpt-loss=0.91-epoch=0004\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.9029 - accuracy: 0.4956WARNING:tensorflow:From /home/yi/anaconda3/envs/python38/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /home/yi/anaconda3/envs/python38/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: ./models/checkpoint/ckpt-loss=0.90-epoch=0005/assets\n",
      "39/39 [==============================] - 42s 1s/step - loss: 0.9029 - accuracy: 0.4956 - val_loss: 0.7098 - val_accuracy: 0.6883\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.9011 - accuracy: 0.4960INFO:tensorflow:Assets written to: ./models/checkpoint/ckpt-loss=0.90-epoch=0006/assets\n",
      "39/39 [==============================] - 45s 1s/step - loss: 0.9011 - accuracy: 0.4960 - val_loss: 0.7080 - val_accuracy: 0.6905\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.8985 - accuracy: 0.4960INFO:tensorflow:Assets written to: ./models/checkpoint/ckpt-loss=0.90-epoch=0007/assets\n",
      "39/39 [==============================] - 41s 1s/step - loss: 0.8985 - accuracy: 0.4960 - val_loss: 0.7064 - val_accuracy: 0.6910\n",
      "Epoch 8/10\n",
      " 1/39 [..............................] - ETA: 0s - loss: 1.1276 - accuracy: 0.6286"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-da5960fd3f5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mvalidate_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidate_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasample_period\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_period\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mband_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0minitial_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m model.fit(itertools.cycle(train_generator), epochs=10, steps_per_epoch=n_train_files, initial_epoch=initial_epoch,\n\u001b[0m\u001b[1;32m     13\u001b[0m           validation_data=itertools.cycle(validate_generator), validation_steps=n_validate_files, callbacks=callbacks )\n",
      "\u001b[0;32m~/anaconda3/envs/python38/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python38/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python38/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python38/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python38/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python38/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/anaconda3/envs/python38/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/envs/python38/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python38/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = make_or_restore_model(datasample_period,feature_columns)\n",
    "callbacks = [\n",
    "    # This callback saves a SavedModel every 100 batches.\n",
    "    # We include the training loss in the folder name.\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_dir + '/ckpt-loss={loss:.2f}-epoch={epoch:04d}',\n",
    "        save_freq='epoch', save_weights_only=False)\n",
    "]\n",
    "train_generator = generate_data(train_dir, datasample_period, prediction_period, feature_columns, band_size)\n",
    "validate_generator = generate_data(validate_dir, datasample_period, prediction_period, feature_columns, band_size)\n",
    "initial_epoch = model.initial_epoch\n",
    "model.fit(itertools.cycle(train_generator), epochs=10, steps_per_epoch=n_train_files, initial_epoch=initial_epoch,\n",
    "          validation_data=itertools.cycle(validate_generator), validation_steps=n_validate_files, callbacks=callbacks )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
